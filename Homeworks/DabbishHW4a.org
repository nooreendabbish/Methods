#+TITLE: 8004 Homework 4
#+AUTHOR: Nooreen Dabbish
#+EMAIL: nerd@temple.edu
#+LATEX_HEADER: \usepackage{methodshw}
#+LATEX_HEADER: \usepackage{booktabs}
#+OPTIONS: toc:nil

# Code to input variables, libraries, and commonly used functions:
#+NAME: common
#+BEGIN_SRC R :session *HW4* :exports none :tangle yes
library(MASS); library(xtable)
  lvector <- function(x, dig = 2, dsply=rep("f",ncol(x)+1)) {
   x <- xtable(x, align=rep("",ncol(x)+1),display=dsply,digits=dig) # We repeat empty string 6 times
   print(x, floating=FALSE, tabular.environment="pmatrix", 
     hline.after=NULL, include.rownames=FALSE, include.colnames=FALSE)
   }

#Variables from Problem 2 of HW3:
  V1 <- diag(c(1,9,9,1,1,9))
  Y <- matrix(c(2, 1, 4, 6, 3, 5), nrow=6, ncol=1)
  X <- matrix(c(rep(1,6),
                1,1,0,0,0,0,
                0,0,1,0,0,0,
                0,0,0,1,0,0,
                0,0,0,0,1,1),nrow = 6,byrow=FALSE)

  V2 <- diag(c(1,9,9,1,1,9))
  V2[1,2] <- 1
  V2[2,1] <- 1
  V2[4,3] <- -1
  V2[3,4] <- -1
  V2[6,5] <- -1
  V2[5,6] <- -1

#+END_SRC

* Problem 1 In the context of Problem 2 of Homework Assignment 3, use R matrix calculations to do the following in the (non-full-rank) Gauss-Markov normal linear model

** Find 90% two-sided confidence limits for \sigma.

*** Background

The model described in HW3, Problem 2 in 
$\mathbf{Y}=\mathbf{X\beta}+\epsilon$ matrix form is:

\[
\begin{pmatrix}
y_{11} \\ y_{12}\\ y_{21}\\ y_{31}\\ y_{41}\\ y_{42}
\end{pmatrix} = 
\begin{pmatrix} 
2\\ 1\\ 4\\ 6\\ 3\\ 5
\end{pmatrix} = 
\begin{pmatrix}
1 & 1 & 0 & 0 & 0 \\
1 & 1 & 0 & 0 & 0 \\
1 & 0 & 1 & 0 & 0 \\
1 & 0 & 0 & 1 & 0 \\
1 & 0 & 0 & 0 & 1 \\
1 & 0 & 0 & 0 & 1 \\
\end{pmatrix}  
\begin{pmatrix}
\mu \\ \tau_1 \\ \tau_2 \\ \tau_3 \\ \tau_4 
\end{pmatrix} + 
\begin{pmatrix}
\epsilon_{11} \\ \epsilon_{12}\\ \epsilon_{21}\\ \epsilon_{31}\\ \epsilon_{41}\\ \epsilon_{42}
\end{pmatrix}
\]

Also, we are given that var(\epsilon)= *V*, for *V_1* =
diag(1,9,9,1,1,9) and \( \mathbf{V_2} = \begin{pmatrix}
1 & 1 & 0 & 0 & 0 & 0 \\
1 & 9 & 0 & 0 & 0 & 0 \\
0 & 0 & 9 & -1& 0 & 0 \\
0 & 0 & -1& 1 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & -1 \\
0 & 0 & 0 & 0 & -1 & 9
\end{pmatrix} \).

We have $\mathbf{Y} \sim N_n(\mathbf{X\beta},\sigma^2\mathbf{V})$. To
find a suitable estimator for \sigma^2, first transform the
Generalized Least Squares model into an Ordinary Least Squares model
by multiplying by *V^{-1/2}*. This gives *U* + *W\beta* =
$\epsilon^{\star}$, where *U* = *V^{-1/2} Y*, *W* = *V^{-1/2} X*, and
$\epsilon^{\star}$ = *V^{-1/2} \epsilon*. Note that $\mathbf{U} \sim
N_n(\mathbf{W\beta}, \sigma^2 \mathbf{I})$. 

Now find an estimator for \sigma^2 for use in construction of the
confidence interval using the variance of *U*. var(*U*) = \sigma^2 *I*
= E(*U* - E(*U*))^2 = E(*U* - *WB*)^2. First observe the distribution
of $\mathbf{U} - \hat{\mathbf{U}} \sim$ N_n(*0*, \sigma^2 *I*). 
Consider $$ \frac{SSE}{\sigma^2} =
\frac{(\mathbf{U}-\hat{\mathbf{U}})'(\mathbf{U}-\hat{\mathbf{U}})}{\sigma^2}
=\frac{1}{\sigma^2}
((\mathbf{I}-\mathbf{P_W})\mathbf{U})'((\mathbf{I}-\mathbf{P_W})\mathbf{U})
= \frac{1}{\sigma^2} \mathbf{U}'(\mathbf{I} -
\mathbf{P_W})\mathbf{U}$$
Note that the product of $\frac{1}{\sigma^2}(\mathbf{I} -
\mathbf{P_W})$ and $cov(\mathbf{U}) = \sigma^2 \mathbf{I}$ is $\mathbf{U} - \hat{\mathbf{U}}$
is  $\frac{1}{\sigma^2}(\mathbf{I} -
\mathbf{P_W}) \sigma^2 \mathbf{I} = (\mathbf{I} - \mathbf{P_W})$.
The result is a projection matrix orthogonal to C(*W*). It is also
idempotent, a property of all projection matrices which can also be
shown: (*I* - *P_W*)(*I* - *P_W*) = *I* - *I P_W* - *P_W I* + *P_W
P_W* = *I* - *P_W*. Further rank(*I-P_W*)=n-rank(*W*)

The following theorem applies to the  quadratic form $\frac{1}{\sigma^2} \mathbf{U}'(\mathbf{I} -
\mathbf{P_W})\mathbf{U}$ and shows that it is distributed
$\chi^2((n-rank(*W*))$.

\begin{theorem} \label{quadnormchisq}
Let \textbf{y} be distributed N_p($\mathbf{\mu}$, $\mathbf{\Sigma}$), \textbf{A} be a symmetric matric of constants, rank(\textbf{A})=r, and define $\lambda = \frac{1}{2} \mathbf{\mu'A\mu}$.
Then, \textbf{y'Ay} follows $\chi^2(r,\lambda)$ if and only if $\mathbf{A\Sigma}$ is idempotent.
\end{theorem}

Here, *y* = *U*, *\mu* = *W\beta*, *\Sigma* = \sigma^2 *I*, *A* =
$\frac{1}{\sigma^2}(\mathbf{I} - \mathbf{P_W})$, and $\lambda =
\frac{1}{2 \sigma^2} \beta'\mathbf{W}'(\mathbf{I} -\mathbf{P_W})\mathbf{W\beta} = \mathbf{0}$. 

To find two-sided 90% confidence limits for \sigma^2, we note SSE
= *U'(I-P_W)U* and write:

1 - \alpha = P(lower $\frac{\alpha}{2}$ quantile of \chi^2(n-rank(*W*)) <
$\frac{SSE}{\sigma^2}$ < upper $\frac{\alpha}{2}$ quantile of \chi^2(n-rank(*W*)))

.90 = P(lower .05 quantile of \chi^2(n-rank(*W*)) <
$\frac{SSE}{\sigma^2}$ < upper .05 quantile of \chi^2(n-rank(*W*)))

Solving for an interval for \sigma^2, we have:

.90 = P($\frac{SSE}{\text{upper .05 quantile of
}\chi^2(n-\text{rank}(\mathbf{W}))}$ < \sigma^2 <
$\frac{SSE}{\text{lower .05 quantile of
}\chi^2(n-\text{rank}(\mathbf{W}))}$))




*** Interval for \sigma^2 using *V_1*

#+BEGIN_SRC R :session *HW4* :exports code :tangle yes
  #Find V^(-1/2)
  Vh1 <-solve(V1^(1/2))

  #Transform model to OLS
  U <- Vh1 %*% Y
  W <- Vh1 %*% X
  
  Uhat <- W %*% ginv(t(W) %*% W) %*% t(W) %*% U
  
  SSE <- t(U-Uhat) %*% (U-Uhat)
  
  qr(W)$rank
  
  lowerchi <- qchisq(.05, df=4)
  upperchi <- qchisq(.95, df=4)
  
  SSE/lowerchi
  SSE/upperchi
#+END_SRC

For the covariance matrix *V_1* given in HW3 problem 2, we found an
SSE of SRC_R[ :session *HW4*]{SSE} and two-sided 90% confidence
limits for \sigma^2 of SRC_R[ :session *HW4*]{round(SSE/upperchi,4)} <
\sigma^2 < SRC_R[ :session *HW4*]{round(SSE/lowerchi,4)}.

*** Interval for \sigma^2 using *V_2*

#+BEGIN_SRC R :session *HW4* :exports code :tangle yes
  #Find V^(-1/2) using spectral decompostion
  Vh2 <-solve(eigen(V2)$vectors %*% diag(sqrt(eigen(V2)$values)) %*% t(eigen(V2)$vectors))
  
  #Transform model to OLS
  U <- Vh2 %*% Y
  W <- Vh2 %*% X
  
  Uhat <- W %*% ginv(t(W) %*% W) %*% t(W) %*% U
  
  SSE <- t(U-Uhat) %*% (U-Uhat)
  
  qr(W)$rank
  
  lowerchi <- qchisq(.05, df=4)
  upperchi <- qchisq(.95, df=4)
  
  
#+END_SRC

For the covariance matrix *V_2* given in HW3 problem 2, we found an
SSE of SRC_R[ :session *HW4*]{round(SSE,4)} and two-sided 90% confidence
limits for \sigma^2 of SRC_R[ :session *HW4*]{round(SSE/upperchi,4)} <
\sigma^2 < SRC_R[ :session *HW4*]{round(SSE/lowerchi,4)}.


**** Find 90% two-sided confidence limits for \mu + \tau_2.

**** Find 90% two-sided confidence limits for \tau_1 - \tau_2.

**** Find a /p/-value for testing the null hypothesis $H_0 : \tau_1 - \tau_2 = 0$ vs /H_a/ : not /H_0/.

**** Find 90% two-sided predition limits for the sample mean of /n/=10 future observations from the first set of conditions.

**** Find 90% two-sided prediction limints for the difference between a pair of future values, one from the first set of conditions (i.e. with mean \mu + \tau_1) and one from the second set of conditions (i.e. with mean \mu + \tau_2).

**** Find a /p/-value for testing the following: What is the practical interpretation of this test?   
\( H_0 : \begin{pmatrix} 0 & 1 & -1 & 0 & 0 \\ 0 & 1 & 0 & -1 & 0 \\ 0 & 1 & 0 & 0 & -1 \end{pmatrix} \begin{pmatrix} \mu \\ \tau_1 \\ \tau_2 \\ \tau_3 \\ \tau_4 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ 0 \end{pmatrix}. \) 
**** Find a /p/-value for testing:
\(H_0 : \begin{pmatrix} 0 & 1 & -1 & 0 & 0 \\ 0 & 0 & 1 & -1 & 0 \end{pmatrix} \begin{pmatrix} \mu \\ \tau_1 \\ \tau_2 \\ \tau_3 \\ \tau_4 \end{pmatrix} = \begin{pmatrix} 10 \\ 0  \end{pmatrix}.\)
* Problem 2 In the following make use of the data in Problem 4 of Homework Assignment 3. Consider a regression of /y/ on $x_1, x_2,\ldots,x_5$. Use R matrix calculations to do the following in a full rank Gauss-Markov normal linear model.
** Find 90% two-sided condifence limits for \sigma.





** Find 90% two-sided condifence limits for the mean response under the conditions of data point #1.

** Find 90% two-sided condifence limits for the difference in mean responses under the conditions of data points #1 and #2. .

** Find a /p/-value for testing the hypothesis that the conditions of data points #1 and #2 produce the same mean response.
** Find 90% two-sided prediction limits for an additional response for the set of conditions $x_1 = 0.005, x_2 = 0.45, x_3 = 7, x_4 = 45,$ and $x_5 = 6$.
** Find a /p/-value for testing the hypothesis that a model including only /x_1/, /x_3/, and /x_5/ is adequare for "explaining" home price. (Hint: write it in the form of /H_0/ : *C\beta = 0*).
* Problem 3
** In the context of Problem 1, part g), suppose that in fact \tau_1 = \tau_2, \tau_3 = \tau_4 = \tau_1 - d\sigma. What is the distribution of the F statistic?
** Use R to plot the power of the \alpha = 0.05 level test as a function of /d/ for /d/ \in [-5,5], that is plotting /P/ (F > the cut-off value) against /d/. The R function pf(q,df1,df2,ncp) will compute cumulative (non-central) F probabilities for you corresponding to the value q, for degrees of freedom df1 and df2 when the noncentrality parameter is ncp.

\newpage
* Appendix: Tangled R code


\lstinputlisting{DabbishHW4a.R}


