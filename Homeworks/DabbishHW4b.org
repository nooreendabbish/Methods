#+TITLE: 8004 Homework 4
#+AUTHOR: Nooreen Dabbish
#+EMAIL: nerd@temple.edu
#+LATEX_HEADER: \usepackage{methodshw}
#+LATEX_HEADER: \usepackage{booktabs}
#+OPTIONS: toc:nil

# Code to input variables, libraries, and commonly used functions:
#+NAME: common
#+BEGIN_SRC R :session *HW4* :exports none :tangle yes
   library(MASS); library(xtable)
     lvector <- function(x, dig = 2, dsply=rep("f",ncol(x)+1)) {
      x <- xtable(x, align=rep("",ncol(x)+1),display=dsply,digits=dig) # We repeat empty string 6 times
      print(x, floating=FALSE, tabular.environment="pmatrix", 
        hline.after=NULL, include.rownames=FALSE, include.colnames=FALSE)
      }
   
   #Variables from Problem 2 of HW3:
     Y1 <- matrix(c(2, 1, 4, 6, 3, 5), nrow=6, ncol=1)
     X1 <- matrix(c(rep(1,6),
                   1,1,0,0,0,0,
                   0,0,1,0,0,0,
                   0,0,0,1,0,0,
                   0,0,0,0,1,1),nrow = 6,byrow=FALSE)
   
   #Variables from Problem 4 of HW3:
   data(Boston)
   YB = as.matrix(Boston$medv)
   XB = as.matrix(Boston[,c('crim','nox','rm','age','dis')])
   XB = cbind(rep(1,dim(Boston)[1]),XB)
   bhatB <- ginv(t(XB)%*%XB) %*% t(XB) %*% YB
   YhatB <- XB %*% bhatB
   errB <- YB - YhatB
   sigsqhatB <- t(errB) %*% errB / (dim(XB)[1] - qr(XB)$rank)
   
   #functions for calculating estimates:
   
   sigmacalc <- function(Y, X, alpha){
   Yh <- X %*% ginv(t(X) %*% X) %*% t(X) %*% Y
   SSE <- t(Y-Yh) %*% (Y-Yh)
   
   lowerchi <- qchisq(alpha/2, df=(length(Y) - qr(X)$rank))
   upperchi <- qchisq(1-alpha/2, df=(length(Y) - qr(X)$rank))
   
   return(c(sqrt(SSE/upperchi),sqrt(SSE/lowerchi)))
   }
   
  X511 <- matrix(c(rep(1,9),rep(c(rep(0,7),1),3),1,1),7,5)
  Y511 <- c(2,1,4,6,3,5,4)
     
   cbetacalc <- function(Y,X, alpha, ct){
   Yh <- X %*% ginv(t(X) %*% X) %*% t(X) %*% Y
   SSE <- t(Y-Yh) %*% (Y-Yh)
   MSE <- SSE/(length(Y) - qr(X)$rank)
   quad <- t(ct)%*%ginv(t(X)%*%X)%*%ct
   
   tstar <- qt(1-alpha/2, length(Y) - qr(X)$rank)
   pm <- tstar  * sqrt(quad) * sqrt (MSE)
   
   ctbhat <- t(ct)%*%ginv(t(X)%*%X)%*%t(X)%*%Y
   
   return(c(ctbhat-pm,ctbhat+pm))
   }
   
   a_1c = matrix(c(0,1,-1,0,0))
   
   cbetacalc(Y511,X511, .1, c(1,1,0,0,0))
   cbetacalc(Y1,X1, .1, c(1,0,1,0,0))
   cbetacalc(Y1,X1, .1, a_1c)
   
  #F-test function:
  
   Cbetahatd <- function (Y,X, ct, d = 0){
   
   CGCinv <- ginv(t(ct)%*%ginv(t(X)%*%(X))%*%ct)
   CBhat <- t(ct)%*%ginv(t(X)%*%X)%*%t(X)%*%Y
   Q <- t(CBhat - d)%*%CGCinv%*%(CBhat-d)
   MSH <- Q/qr(ct)$rank
  
   Yhat <- X %*% ginv(t(X)%*%X)%*%t(X)%*%Y
   SSE <- t(Y-Yhat)%*%(Y-Yhat)
   MSE <- SSE/(length(Y) - qr(X)$rank)
  
   F <- MSH/MSE
  
   return(1-pf(F, qr(ct)$rank, length(Y)-qr(X)$rank))
   
   }
  
  
   Cbetahatd(Y1, X1, c(0,1,-1,0,0))
  
  G <- t(matrix(c(0, 1, -1, 0, 0, 0, 1, 0, -1, 0, 0, 1, 0, 0, -1), nrow=3, ncol=5, byrow=TRUE))
  
   Cbetahatd(Y511, X511, G, c(0,0,0))
  
  H <- t(matrix(c(0, 1, -1, 0, 0, 0, 0, 1, -1, 0), nrow=2, ncol=5, byrow=T))
  
   Cbetahatd(Y1, X1, H, c(10,0))
  
  
   homes<- read.table("http://www.public.iastate.edu/~vardeman/stat511/homes.TXT",header=T) 
   Yhomes <-as.matrix(homes[,1])
   Xhomes <-as.matrix(homes[,c(2,5,10,11,13)]) 
   Xhomes <- cbind(rep(1,length(Yhomes)),Xhomes)
  
   C2g <- c(0,0,1,0,1,0)
   Cbetahatd(Yhomes, Xhomes,C2g)
  
#+END_SRC

#+RESULTS: common
: 4.56960612884975


* Problem 1 In the context of Problem 2 of Homework Assignment 3, use R matrix calculations to do the following in the (non-full-rank) Gauss-Markov normal linear model
** Find 90% two-sided confidence limits for \sigma.

The model described in HW3, Problem 2 in 
$\mathbf{Y}=\mathbf{X\beta}+\epsilon$ matrix form is:

\[
\begin{pmatrix}
y_{11} \\ y_{12}\\ y_{21}\\ y_{31}\\ y_{41}\\ y_{42}
\end{pmatrix} = 
\begin{pmatrix} 
2\\ 1\\ 4\\ 6\\ 3\\ 5
\end{pmatrix} = 
\begin{pmatrix}
1 & 1 & 0 & 0 & 0 \\
1 & 1 & 0 & 0 & 0 \\
1 & 0 & 1 & 0 & 0 \\
1 & 0 & 0 & 1 & 0 \\
1 & 0 & 0 & 0 & 1 \\
1 & 0 & 0 & 0 & 1 \\
\end{pmatrix}  
\begin{pmatrix}
\mu \\ \tau_1 \\ \tau_2 \\ \tau_3 \\ \tau_4 
\end{pmatrix} + 
\begin{pmatrix}
\epsilon_{11} \\ \epsilon_{12}\\ \epsilon_{21}\\ \epsilon_{31}\\ \epsilon_{41}\\ \epsilon_{42}
\end{pmatrix}
\]

Because the problem statement says this is a Gauss-Markov normal
linear model, we know that *Y* \sim N(*X\beta*,\sigma^2 *I*).

#+BEGIN_SRC R :session *HW4* :exports code :tangle yes
  Yhat <- X %*% ginv(t(X) %*% X) %*% t(X) %*% Y
  
  SSE1a3 <- t(Y-Yhat) %*% (Y-Yhat)
  
  lowerchi <- qchisq(.05, df=(length(Y) - qr(X)$rank))
  upperchi <- qchisq(.95, df=(length(Y) - qr(X)$rank))
  
#+END_SRC

#+RESULTS:
: 5.99146454710798

For the Gauss-Markov linear model of HW3 Problem 2, we found an SSE of SRC_R[ :session *HW4*]{round(SSE1a3,4)} and two-sided 90% confidence
limits for \sigma of SRC_R[ :session *HW4*]{round(sqrt(SSE1a3/upperchi),4)} <
\sigma < SRC_R[ :session *HW4*]{round(sqrt(SSE1a3/lowerchi),4)}.

** Find 90% two-sided confidence limits for \mu + \tau_2.
:PROPERTIES:
:CUSTOM_ID: MuTau2
:END:
The following provides 90% confidence limits for \mu + \tau_2 in the
Gauss-Markov model first, where *Y* \sim N_6(*X\beta*, \sigma^2 *I*) and then in the GLS cases with var(*Y*) =
\sigma^2 *V_1* and var(*Y*) = \sigma^2 *V_2*.

** Find 90% two-sided confidence limits for \tau_1 - \tau_2.
:PROPERTIES:
:CUSTOM_ID: Tau1Tau2
:END:
Proceeding as in [[#MuTau2][part b]], here \tau_1 - \tau_2 = *a*'*\beta* = $(0, 1, -1,
0, 0) \begin{pmatrix} \mu \\ \tau_1 \\ \tau_2
\\ \tau_3 \\ \tau_4 \end{pmatrix}$. Note that the quantile for
/t_{\alpha/2}/ and value for /s/ are calculated above.

#+BEGIN_SRC R :session *HW4* :exports code :tangle yes
 
  a_1c = matrix(c(0,1,-1,0,0))
  
  quad_1c <- sqrt(t(a_1c) %*% ginv(t(W)%*%W) %*% a_1c)
  upper1c <- t(a_1c) %*% Bhat_1b - t_1b * s_1b * quad_1c
  lower1c <- t(a_1c) %*% Bhat_1b + t_1b * s_1b * quad_1c
  
#+END_SRC

We find that the 90% confidence limits for \tau_1 - \tau_2 are from SRC_R[ :session *HW4* :tangle yes]{round(lower1c,4)} to SRC_R[ :session *HW4* :tangle yes]{round(upper1c,4)}. 

** Find a /p/-value for testing the null hypothesis $H_0 : \tau_1 - \tau_2 = 0$ vs /H_a/ : not /H_0/.
:PROPERTIES:
:CUSTOM_ID: Tau1Tau2H0
:END:

*** General Linear Hypothesis Test
/The general linear hypothesis test/ is the following F test for
/H_0/ : *C\beta* = *0* verus /H_1/ : *C\beta* \neq *0*, given *y*
\sim N_n(*X\beta*,\sigma^2 *I*), *C* /q/ x (/k/+1), rank(*C*) = q, with SSH = the sum of squares due to
the hypothesis or due to *C\beta*. Note that 

\(\frac{SSH}{\sigma^2} = \frac{(\mathbf{C\hat{\beta}})'[\mathbf{C(X'X)^{-1}C}']^{-1}\mathbf{C\hat{\beta}}}{\sigma^2}
\sim
\chi^2(q,\frac{(\mathbf{C\beta})'[\mathbf{C(X'X)^{-1}C}']^{-1}\mathbf{C\beta}}{2\sigma^2})\)

\noindent and

\(\frac{SSE}{\sigma^2} = \frac{\mathbf{y}'[\mathbf{I} -
\mathbf{X(X'X)^{-1}X}']\mathbf{y}}{\sigma^2} \sim \chi^2(n-k-1).\)

Taking the ratio gives us our test statistic:
$$F = \frac{SSH/q}{SSE/(n-k-1)}$$

+ If /H_0/ : *C\beta* = *0* is false, F \sim F(q,n-k-1,\lambda), where
  $\lambda =
  \frac{(\mathbf{C\beta})'[\mathbf{C(X'X)^{-1}C}']^{-1}\mathbf{C\beta}}{2\sigma^2})$.

+ Notice that if *C\beta* = *0* is true, \lambda defined above = 0, giving F
  \sim F(q, n-k-1). 

*** /p/-value from the F statistic

We need to find the F statistic described above. Here *C* is *a*' from [[#Tau1Tau2][above]], *a*'=(0,1,-1,0,0), and *C* is 1 x 5 of
rank 1, so q = 1. Note also that n=6, k=4, n-k-1=1.

#+BEGIN_SRC R :session *HW4* :exports code :tangle yes
  
  SSH <- t(t(a_1c) %*% Bhat_1b) %*% ginv(t(a_1c)%*%ginv(t(W)%*%W)%*%a_1c)%*%t(a_1c)%*%Bhat_1b
  
  p_1d <- pf(SSH/SSE, 1, 1, lower.tail=FALSE)
  
#+END_SRC

The /p/-value obtained was SRC_R[ :session *HW4* :tangle yes]{round(p_1d,4)}. This is the probability that the central F
distribution exceeds the observed F. This suggests that we should accept the null
hyposthesis.

** Find 90% two-sided predition limits for the sample mean of /n/=10 future observations from the first set of conditions.

*** A t statistic for prediction

Consider future observation y_0, y_0 = *x_0*' \beta + \epsilon_0 with
$\hat{y}_0 = \mathbf{x_0'\hat{\beta}}$, where $\hat{y_0}$ is computed
from /n/ observations and y_0 is obtained independently. We find that
$E(y_0 - \hat{y_0}) = 0$ and 


$var(y_0 - \hat{y}_0) = var(\epsilon_0) +
var(\mathbf{x_0'\hat{\beta}}) = \sigma^2[1+
\mathbf{x_0'(X'X)^{-1}x_0}]$, where 
$\widehat{var(y - \hat{y}_0)} = s^22[1+ \mathbf{x_0'(X'X)^{-1}x_0}]$. Because of the independence of /s^2/
and /y_0/ and $\hat{y}_0$, we have the following t statistic:

$$t = \frac{y_0 - \hat{y}_0 - 0}{s\sqrt{1+
\mathbf{x_0'(X'X)^{-1}x_0}} \sim t(n-k-1)}$$



Therefore,

$$P = \left[ -t_{\alpha/2,n-k-1} \leq \frac{y_0 - \hat{y}_0 - 0}{s\sqrt{1+
\mathbf{x_0'(X'X)^{-1}x_0}}} \leq t_{alpha/2,n-k-a}\right] = 1 -
\alpha$$

Re-arranging in terms of $\mathbf{x_0'\hat{\beta}} = \hat{y}_0$ gives:

$$\mathbf{x_0'\hat{\beta}} \pm t_{\alpha/2,n-k-1}s\sqrt{1+
\mathbf{x_0'(X'X)^{-1}x_0}}.$$

** Find 90% two-sided prediction limits for the difference between a pair of future values, one from the first set of conditions (i.e. with mean \mu + \tau_1) and one from the second set of conditions (i.e. with mean \mu + \tau_2).

** Find a /p/-value for testing the following: What is the practical interpretation of this test?   
\( H_0 : \begin{pmatrix} 0 & 1 & -1 & 0 & 0 \\ 0 & 1 & 0 & -1 & 0 \\ 0 & 1 & 0 & 0 & -1 \end{pmatrix} \begin{pmatrix} \mu \\ \tau_1 \\ \tau_2 \\ \tau_3 \\ \tau_4 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ 0 \end{pmatrix}. \) 
** Find a /p/-value for testing:
\(H_0 : \begin{pmatrix} 0 & 1 & -1 & 0 & 0 \\ 0 & 0 & 1 & -1 & 0
\end{pmatrix} \begin{pmatrix} \mu \\ \tau_1 \\ \tau_2 \\ \tau_3
\\ \tau_4 \end{pmatrix} = \begin{pmatrix} 10 \\ 0  \end{pmatrix}.\)

* Problem 2 In the following make use of the data in Problem 4 of Homework Assignment 3. Consider a regression of /y/ on $x_1, x_2,\ldots,x_5$. Use R matrix calculations to do the following in a full rank Gauss-Markov normal linear model.
** Find 90% two-sided condifence limits for \sigma.




** Find 90% two-sided condifence limits for the mean response under the conditions of data point #1.

** Find 90% two-sided condifence limits for the difference in mean responses under the conditions of data points #1 and #2. .

** Find a /p/-value for testing the hypothesis that the conditions of data points #1 and #2 produce the same mean response.
** Find 90% two-sided prediction limits for an additional response for the set of conditions $x_1 = 0.005, x_2 = 0.45, x_3 = 7, x_4 = 45,$ and $x_5 = 6$.
** Find a /p/-value for testing the hypothesis that a model including only /x_1/, /x_3/, and /x_5/ is adequare for "explaining" home price. 
(Hint: write it in the form of /H_0/ : *C\beta = 0* ).
 The full model in this problem is /y/ = \beta_0 + \beta_1 x_1 +
 \beta_2 x_2 + \beta_3 x_3 + \beta_4 x_4 + \beta_5 x_5 + \epsilon. 
 The reduced model to test is /H_0/ : \beta_2 = \beta_4 = 0 or /y/ =
 \beta_0 + \beta_1 x_1 + \beta_3 x_3 + \beta_5 x_5 + \epsilon. This can be written *C\beta = 0*, with C = (0 0 1 0 1 0).

We can create a /p/-value to test these models using an F statistic,
constructed out of the ratio of the difference in regression sum of
squares between the full (SSR_{full}) and reduced(SSR_{reduced}) models and the sum of squared
error (SSE). These quantities are independent and follow a
non-central \chi^2(/h/,\lambda) and central \chi^2(/n-k-1/)
respectively where /n/ is the number of observations, /k/ is the
number of parameters in the full model, and /h/ is the difference in the
number of parameters between the full and reduced models. The
non-centrality parameter \lambda can be written *\beta_2'[X_2'X_2 -
X_2'X_1(X_1'X_1)^{-1}X_1'X_2]\beta_2/2\sigma^2* where *X_1* and *X_2*
form a partition of *X* such that we can write: $$\mathbf{y} =
\mathbf{X\beta} + \mathbf{\epsilon} =
(\mathbf{X}_1,\mathbf{X}_2)\begin{pmatrix} \mathbf{\beta}_1
\\ \mathbf{\beta}_2 \end{pmatrix} + \mathbf{\epsilon} =
\mathbf{X}_1\mathbf{\beta}_1 + \mathbf{X}_2\mathbf{\beta}_2 +
\mathbf{\epsilon} $$

And the reduced model would be *y* = *X_1\beta_1^{\star}* + \epsilon^{\star}.


#+BEGIN_SRC R :session *HW4* :exports code :tangle yes
  #Find SSR in the full model.
  SSR_Bf <- t(bhat_B) %*% t(X_B) %*% Y_B - (length(Y_B)*(mean(Y_B))^2)
  
  #create reduced model design matric and X1_B and estimator bhat1_B
  X1_B <- X_B[,-c(3,5)]
  bhat1_B <- ginv(t(X1_B)%*%X1_B) %*% t(X1_B) %*% Y_B
  SSR_Br <- t(bhat1_B) %*% t(X1_B) %*% Y_B - (length(Y_B)*(mean(Y_B))^2)
  
  SSE_B <- t(Y_B)%*%Y_B - t(bhat_B)%*%t(X_B)%*%Y_B
  
  F_2f <- ((SSR_Bf - SSR_Br)/2)/(SSE_B/(length(Y_B) - qr(X_B)$rank))
  
  pf_2f <- pf(F_2f, 2, (length(Y_B)-(qr(X_B)$rank)), lower.tail=F)
  pf_2f
#+END_SRC

This gives us a /p/-value of SRC_R[ :session *HW4* :tangle yes]{pf_2f}.





*  Problem 3
** In the context of Problem 1, part g), suppose that in fact \tau_1 = \tau_2, \tau_3 = \tau_4 = \tau_1 - d\sigma. What is the distribution of the F statistic?
** Use R to plot the power of the \alpha = 0.05 level test as a function of /d/ for /d/ \in [-5,5], that is plotting /P/ (F > the cut-off value) against /d/. The R function pf(q,df1,df2,ncp) will compute cumulative (non-central) F probabilities for you corresponding to the value q, for degrees of freedom df1 and df2 when the noncentrality parameter is ncp.

\newpage
* Appendix: Tangled R code
:PROPERTIES:
:UNNUMBERED: t
:END:

\lstinputlisting{DabbishHW4a.R}


